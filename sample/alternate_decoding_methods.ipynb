{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=torch_device)\n",
    "    print (x)\n",
    "else:\n",
    "    torch_device = torch.device(\"cpu\")\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "EMBEDDING_DIM = 3\n",
    "CONTEXT_LENGTH = 4\n",
    "QKV_DIM = 2\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length=CONTEXT_LENGTH, dropout=0.5, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.w_q = nn.Linear(d_in, d_out, bias=qkv_bias).to(torch_device)\n",
    "        self.w_k = nn.Linear(d_in, d_out, bias=qkv_bias).to(torch_device)\n",
    "        self.w_v = nn.Linear(d_in, d_out, bias=qkv_bias).to(torch_device)\n",
    "        self.dropout = nn.Dropout(dropout).to(torch_device)\n",
    "        self.register_buffer(\n",
    "            'mask', \n",
    "            torch.triu(\n",
    "                torch.ones(context_length, context_length), \n",
    "                diagonal=1,\n",
    "            ).to(torch_device)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_tokens = x.shape[-2]\n",
    "        queries = self.w_q(x)\n",
    "        keys = self.w_k(x)\n",
    "        attn_scores = queries @ keys.transpose(-2, -1)\n",
    "        causal_attn_scores = attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        causal_attn_weights = torch.softmax(causal_attn_scores*(self.d_out**0.5), dim=-1)\n",
    "        causal_attn_weights = self.dropout(causal_attn_weights)\n",
    "        values = self.w_v(x)\n",
    "        context = causal_attn_weights @ values\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "EMBEDDING_DIM = 3\n",
    "CONTEXT_LENGTH = 4\n",
    "QKV_DIM = 2\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out//num_heads\n",
    "        self.w_q = nn.Linear(d_in, d_out, bias=qkv_bias).to(torch_device)\n",
    "        self.w_k = nn.Linear(d_in, d_out, bias=qkv_bias).to(torch_device)\n",
    "        self.w_v = nn.Linear(d_in, d_out, bias=qkv_bias).to(torch_device)\n",
    "        self.w_o = nn.Linear(d_out, d_out).to(torch_device)\n",
    "        # self.w_o = nn.Identity().to(torch_device)\n",
    "        self.dropout = nn.Dropout(dropout).to(torch_device)\n",
    "        self.register_buffer(\n",
    "            'mask', \n",
    "            torch.triu(\n",
    "                torch.ones(context_length, context_length), \n",
    "                diagonal=1,\n",
    "            ).to(torch_device)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.w_k(x)\n",
    "        queries = self.w_q(x)\n",
    "        values = self.w_v(x)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(-3, -2)\n",
    "        # TODO: KV Cache Optimization\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(-3, -2)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(-3, -2)\n",
    "        attn_scores = queries @ keys.transpose(-2, -1)\n",
    "        causal_attn_scores = attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        causal_attn_weights = torch.softmax(causal_attn_scores/(keys.shape[-1]**0.5), dim=-1)\n",
    "        causal_attn_weights = self.dropout(causal_attn_weights)\n",
    "        context = (causal_attn_weights @ values).transpose(-3, -2)\n",
    "        context = context.contiguous().view(b, num_tokens, self.num_heads*self.head_dim)\n",
    "        context = self.w_o(context)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(d_model))\n",
    "        self.shift = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True, unbiased=False)\n",
    "        x = (self.scale * (x - mean) / (std + self.eps)) + self.shift\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (\n",
    "            1 + torch.tanh(\n",
    "                torch.sqrt(torch.tensor(2.0/torch.pi, device=torch_device)) * (x  + 0.044715 * x**3)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward (nn.Module):\n",
    "    def __init__(self, cfg): \n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"]*4).to(torch_device),\n",
    "            GELU().to(torch_device),\n",
    "            nn.Linear(cfg[\"emb_dim\"]*4, cfg[\"emb_dim\"]).to(torch_device),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config[\"emb_dim\"]).to(torch_device)\n",
    "        self.attn = MultiHeadAttention(config[\"emb_dim\"], config[\"emb_dim\"], config[\"context_length\"], config[\"drop_rate\"], config[\"n_heads\"], config[\"qkv_bias\"]).to(torch_device)\n",
    "        self.drop = nn.Dropout(config[\"drop_rate\"]).to(torch_device)\n",
    "        self.ln2 = LayerNorm(config[\"emb_dim\"]).to(torch_device)\n",
    "        self.ff = FeedForward(config).to(torch_device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(self.attn(self.ln1(x))) + x\n",
    "        x = self.drop(self.ff(self.ln2(x))) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"]).to(torch_device)\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"]).to(torch_device)\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"]).to(torch_device)\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        ).to(torch_device)\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"]).to(torch_device)\n",
    "        # GPT2 uses tied weights for the embedding and output layers\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False).to(torch_device)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        in_idx = in_idx.to(torch_device)\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=torch_device))\n",
    "        x = self.drop_emb(tok_embeds + pos_embeds)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, token_ids, max_new_tokens, context_size):\n",
    "    logits = None\n",
    "    for i in range(max_new_tokens):\n",
    "        context_token_ids = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(context_token_ids)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        token_id_next = torch.argmax(probas, dim=1, keepdim=True)  # Pure Greed\n",
    "        token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "\n",
    "    return token_ids\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special=set(['<|endoftext|>']))\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0).to(torch_device)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, targets):\n",
    "    vocab_size = logits.shape[-1]\n",
    "    loss = nn.CrossEntropyLoss()(logits.view(-1, vocab_size), targets.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "#     def __init__(self, txt, tokenizer, max_length, stride):\n",
    "#         self.input_ids = []\n",
    "#         self.target_ids = []\n",
    "#         token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "#         token_ids = token_ids\n",
    "#         token_ids = torch.tensor(token_ids).to(torch_device)\n",
    "#         print(token_ids.shape)\n",
    "#         token_sequences = token_ids.unfold(0, max_length, stride)\n",
    "#         self.input_ids = token_sequences[:-1]\n",
    "#         self.target_ids = token_sequences[1:]\n",
    "\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(\n",
    "        txt, batch_size=4, max_length=256, \n",
    "        stride=128, shuffle=True, drop_last=True,\n",
    "        num_workers=0,\n",
    "    ):\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    return DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device=torch_device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.view(-1, logits.shape[-1]), \n",
    "        target_batch.view(-1),\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(dataloader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "    for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_dataloader, test_dataloader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_dataloader, model, device, num_batches=eval_iter)\n",
    "        test_loss = calc_loss_loader(test_dataloader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, test_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    token_ids = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, token_ids, 50, context_size)\n",
    "    decoded_text = tokenizer.decode(token_ids[0].tolist())\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model, train_dataloader, test_dataloader,\n",
    "    optimizer, device, num_epochs,\n",
    "    eval_freq, eval_iter, start_context, tokenizer\n",
    "):\n",
    "    train_losses, test_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            # print(input_batch)\n",
    "            # print(target_batch)\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            # grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            # print(f\"Gradient norm: {grad_norm:.4f}\")\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step %eval_freq == 0:\n",
    "                train_loss, test_loss = evaluate_model(\n",
    "                    model, train_dataloader, test_dataloader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                test_losses.append(test_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Epoch {epoch + 1} (Step {global_step:06d}): \"\n",
    "                    f\"Train Loss: {train_loss:.3f}, \"\n",
    "                    f\"Val Loss: {test_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, test_losses, track_tokens_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "train_ratio = 0.9\n",
    "split_idx = int(len(raw_text) * train_ratio)\n",
    "train_data = raw_text[:split_idx]\n",
    "test_data = raw_text[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_dataloader = create_dataloader_v1(train_data, batch_size=2, max_length=GPT_CONFIG_124M[\"context_length\"], stride=GPT_CONFIG_124M[\"context_length\"], shuffle=True)\n",
    "test_dataloader = create_dataloader_v1(test_data, batch_size=2, max_length=GPT_CONFIG_124M[\"context_length\"], stride=GPT_CONFIG_124M[\"context_length\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[:100], test_data[:100]\n",
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# tokenizer.encode(train_data[:100], allowed_special={\"<|endoftext|>\"})\n",
    "# len(train_dataloader), len(test_dataloader)\n",
    "# input_sample, target_sample = next(iter(train_dataloader))\n",
    "# torch.sum(input_sample[1]), torch.sum(target_sample[1])\n",
    "# input_sample.shape, \n",
    "# input_sample[1],target_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "gpt = GPTModel(GPT_CONFIG_124M).to(torch_device)\n",
    "# gpt = torch.compile(gpt).to(torch_device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    gpt.parameters(),\n",
    "    lr = 0.0004, weight_decay = 0.1\n",
    ")\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train Loss: 9.817, Val Loss: 9.924\n",
      "Epoch 1 (Step 000005): Train Loss: 8.066, Val Loss: 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Epoch 2 (Step 000010): Train Loss: 6.619, Val Loss: 7.042\n",
      "Epoch 2 (Step 000015): Train Loss: 6.046, Val Loss: 6.596\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Epoch 3 (Step 000020): Train Loss: 6.042, Val Loss: 6.630\n",
      "Epoch 3 (Step 000025): Train Loss: 6.002, Val Loss: 6.664\n",
      "Every effort moves you, the, the, the, the, the,, the, the, the, the,,, the,, the,,, the,, the,,, the, the,, the, the,,,,, the\n",
      "Epoch 4 (Step 000030): Train Loss: 6.009, Val Loss: 6.698\n",
      "Epoch 4 (Step 000035): Train Loss: 6.026, Val Loss: 6.727\n",
      "Every effort moves you                                                  \n",
      "Epoch 5 (Step 000040): Train Loss: 5.969, Val Loss: 6.742\n",
      "Every effort moves you,                                                 \n",
      "Epoch 6 (Step 000045): Train Loss: 5.993, Val Loss: 6.761\n",
      "Epoch 6 (Step 000050): Train Loss: 5.997, Val Loss: 6.776\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Epoch 7 (Step 000055): Train Loss: 6.030, Val Loss: 6.800\n",
      "Epoch 7 (Step 000060): Train Loss: 5.988, Val Loss: 6.814\n",
      "Every effort moves you                                                  \n",
      "Epoch 8 (Step 000065): Train Loss: 5.954, Val Loss: 6.798\n",
      "Epoch 8 (Step 000070): Train Loss: 6.010, Val Loss: 6.804\n",
      "Every effort moves you,                                                 \n",
      "Epoch 9 (Step 000075): Train Loss: 5.977, Val Loss: 6.807\n",
      "Epoch 9 (Step 000080): Train Loss: 5.993, Val Loss: 6.828\n",
      "Every effort moves you,                                                 \n",
      "Epoch 10 (Step 000085): Train Loss: 5.964, Val Loss: 6.847\n",
      "Every effort moves you                                                  \n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses, track_tokens_seen = train_model_simple(\n",
    "    gpt, train_dataloader, test_dataloader, optimizer, torch_device,\n",
    "    num_epochs, eval_freq=5, eval_iter=5, start_context=\"Every effort moves you\", tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, test_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, test_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, track_tokens_seen, train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(model, token_ids, max_new_tokens, context_size):\n",
    "    logits = None\n",
    "    for i in range(max_new_tokens):\n",
    "        context_token_ids = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(context_token_ids)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        token_id_next = torch.argmax(probas, dim=1, keepdim=True)  # Pure Greed\n",
    "        token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "\n",
    "    return token_ids\n",
    "\n",
    "def generate_and_print_with_decoding(model, tokenizer, device, start_context, decoding_fn):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    token_ids = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = decoding_fn(model, token_ids, 50, context_size)\n",
    "    decoded_text = tokenizer.decode(token_ids[0].tolist())\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you                                                  \n"
     ]
    }
   ],
   "source": [
    "generate_and_print_with_decoding(gpt, tokenizer, torch_device, \"Every effort moves you\", greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_tokens(model, token_ids, max_new_tokens, context_size, top_k=5):\n",
    "    logits = None\n",
    "    for i in range(max_new_tokens):\n",
    "        context_token_ids = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(context_token_ids)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        token_id_next = torch.multinomial(probas, num_samples=1)  # Pure Random\n",
    "        token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "        # Print the top-k tokens\n",
    "        topk_probs, topk_tokens = torch.topk(probas, top_k, dim=-1)\n",
    "        for topk_prob, topk_token in zip(topk_probs[0], topk_tokens[0]):\n",
    "            token_str = tokenizer.decode([topk_token])\n",
    "            print(f\"{token_str}: {topk_prob:.4f}\")\n",
    "    \n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(model, token_ids, max_new_tokens, context_size, temperature=1.0):\n",
    "    logits = None\n",
    "    if temperature == 0:\n",
    "        return greedy(model, token_ids, max_new_tokens, context_size)\n",
    "    for i in range(max_new_tokens):\n",
    "        context_token_ids = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(context_token_ids)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits/temperature, dim=-1)\n",
    "        token_id_next = torch.multinomial(probas, num_samples=1)  # Pure Random\n",
    "        token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ": 0.0494\n",
      ",: 0.0380\n",
      ".: 0.0312\n",
      " the: 0.0312\n",
      "--: 0.0194\n",
      "\n",
      ": 0.0456\n",
      ",: 0.0375\n",
      " the: 0.0326\n",
      ".: 0.0319\n",
      "--: 0.0190\n",
      "\n",
      ": 0.0477\n",
      ",: 0.0385\n",
      ".: 0.0315\n",
      " the: 0.0303\n",
      "--: 0.0192\n",
      "\n",
      ": 0.0450\n",
      ",: 0.0379\n",
      ".: 0.0326\n",
      " the: 0.0323\n",
      "--: 0.0193\n",
      "\n",
      ": 0.0430\n",
      ",: 0.0386\n",
      ".: 0.0325\n",
      " the: 0.0324\n",
      "--: 0.0194\n",
      "\n",
      ": 0.0464\n",
      ",: 0.0377\n",
      " the: 0.0320\n",
      ".: 0.0318\n",
      "--: 0.0193\n",
      "\n",
      ": 0.0423\n",
      ",: 0.0392\n",
      ".: 0.0331\n",
      " the: 0.0322\n",
      "--: 0.0191\n",
      "\n",
      ": 0.0450\n",
      ",: 0.0382\n",
      ".: 0.0323\n",
      " the: 0.0315\n",
      "--: 0.0197\n",
      "\n",
      ": 0.0429\n",
      ",: 0.0388\n",
      ".: 0.0325\n",
      " the: 0.0325\n",
      "--: 0.0192\n",
      "\n",
      ": 0.0419\n",
      ",: 0.0398\n",
      " the: 0.0326\n",
      ".: 0.0321\n",
      "--: 0.0198\n",
      "\n",
      ": 0.0407\n",
      ",: 0.0402\n",
      ".: 0.0334\n",
      " the: 0.0322\n",
      "--: 0.0195\n",
      "\n",
      ": 0.0590\n",
      ",: 0.0361\n",
      ".: 0.0303\n",
      " the: 0.0297\n",
      "--: 0.0189\n",
      "\n",
      ": 0.0415\n",
      ",: 0.0385\n",
      ".: 0.0333\n",
      " the: 0.0322\n",
      "--: 0.0195\n",
      "\n",
      ": 0.0416\n",
      ",: 0.0405\n",
      ".: 0.0338\n",
      " the: 0.0317\n",
      "--: 0.0192\n",
      "\n",
      ": 0.0417\n",
      ",: 0.0384\n",
      ".: 0.0345\n",
      " the: 0.0325\n",
      "--: 0.0193\n",
      "\n",
      ": 0.0400\n",
      ",: 0.0393\n",
      ".: 0.0326\n",
      " the: 0.0321\n",
      "--: 0.0196\n",
      ",: 0.0401\n",
      "\n",
      ": 0.0384\n",
      ".: 0.0342\n",
      " the: 0.0330\n",
      "--: 0.0194\n",
      ",: 0.0413\n",
      "\n",
      ": 0.0394\n",
      " the: 0.0328\n",
      ".: 0.0325\n",
      "--: 0.0193\n",
      "\n",
      ": 0.0447\n",
      ",: 0.0389\n",
      " the: 0.0320\n",
      ".: 0.0317\n",
      "--: 0.0195\n",
      "\n",
      ": 0.0415\n",
      ",: 0.0396\n",
      " the: 0.0330\n",
      ".: 0.0329\n",
      "--: 0.0196\n",
      ",: 0.0408\n",
      "\n",
      ": 0.0395\n",
      ".: 0.0334\n",
      " the: 0.0325\n",
      "--: 0.0196\n",
      ",: 0.0406\n",
      "\n",
      ": 0.0397\n",
      ".: 0.0330\n",
      " the: 0.0322\n",
      "--: 0.0195\n",
      "\n",
      ": 0.0417\n",
      ",: 0.0396\n",
      ".: 0.0330\n",
      " the: 0.0327\n",
      "--: 0.0194\n",
      "\n",
      ": 0.0413\n",
      ",: 0.0398\n",
      ".: 0.0333\n",
      " the: 0.0318\n",
      "--: 0.0191\n",
      "\n",
      ": 0.0409\n",
      ",: 0.0405\n",
      ".: 0.0330\n",
      " the: 0.0319\n",
      "--: 0.0197\n",
      "\n",
      ": 0.0425\n",
      ",: 0.0388\n",
      " the: 0.0331\n",
      ".: 0.0329\n",
      "--: 0.0193\n",
      "\n",
      ": 0.0412\n",
      ",: 0.0395\n",
      ".: 0.0331\n",
      " the: 0.0328\n",
      "--: 0.0195\n",
      ",: 0.0414\n",
      "\n",
      ": 0.0396\n",
      ".: 0.0336\n",
      " the: 0.0320\n",
      "--: 0.0196\n",
      "\n",
      ": 0.0402\n",
      ",: 0.0391\n",
      ".: 0.0337\n",
      " the: 0.0318\n",
      "--: 0.0193\n",
      "\n",
      ": 0.0399\n",
      ",: 0.0389\n",
      ".: 0.0334\n",
      " the: 0.0334\n",
      "--: 0.0192\n",
      ",: 0.0412\n",
      "\n",
      ": 0.0371\n",
      ".: 0.0336\n",
      " the: 0.0332\n",
      "--: 0.0194\n",
      ",: 0.0403\n",
      "\n",
      ": 0.0388\n",
      ".: 0.0334\n",
      " the: 0.0327\n",
      "--: 0.0196\n",
      "\n",
      ": 0.0553\n",
      ",: 0.0365\n",
      " the: 0.0310\n",
      ".: 0.0306\n",
      "--: 0.0190\n",
      ",: 0.0399\n",
      "\n",
      ": 0.0397\n",
      ".: 0.0332\n",
      " the: 0.0330\n",
      "--: 0.0197\n",
      ",: 0.0402\n",
      "\n",
      ": 0.0378\n",
      " the: 0.0357\n",
      ".: 0.0335\n",
      "--: 0.0194\n",
      ",: 0.0405\n",
      "\n",
      ": 0.0397\n",
      ".: 0.0332\n",
      " the: 0.0327\n",
      "--: 0.0193\n",
      "\n",
      ": 0.0471\n",
      ",: 0.0380\n",
      ".: 0.0328\n",
      " the: 0.0322\n",
      "--: 0.0194\n",
      "\n",
      ": 0.0561\n",
      ",: 0.0362\n",
      ".: 0.0305\n",
      " the: 0.0303\n",
      "--: 0.0191\n",
      "\n",
      ": 0.0407\n",
      ",: 0.0396\n",
      ".: 0.0336\n",
      " the: 0.0334\n",
      "--: 0.0193\n",
      ",: 0.0404\n",
      "\n",
      ": 0.0396\n",
      ".: 0.0338\n",
      " the: 0.0327\n",
      "--: 0.0192\n",
      ",: 0.0419\n",
      "\n",
      ": 0.0365\n",
      ".: 0.0334\n",
      " the: 0.0326\n",
      "--: 0.0192\n",
      ",: 0.0405\n",
      "\n",
      ": 0.0369\n",
      ".: 0.0341\n",
      " the: 0.0338\n",
      "--: 0.0193\n",
      ",: 0.0412\n",
      "\n",
      ": 0.0383\n",
      ".: 0.0333\n",
      " the: 0.0331\n",
      "--: 0.0198\n",
      ",: 0.0405\n",
      "\n",
      ": 0.0375\n",
      ".: 0.0339\n",
      " the: 0.0331\n",
      "--: 0.0195\n",
      "\n",
      ": 0.0467\n",
      ",: 0.0359\n",
      " the: 0.0323\n",
      ".: 0.0309\n",
      "--: 0.0193\n",
      ",: 0.0401\n",
      "\n",
      ": 0.0389\n",
      ".: 0.0344\n",
      " the: 0.0330\n",
      "--: 0.0192\n",
      ",: 0.0409\n",
      "\n",
      ": 0.0377\n",
      ".: 0.0342\n",
      " the: 0.0332\n",
      "--: 0.0195\n",
      ",: 0.0414\n",
      "\n",
      ": 0.0387\n",
      ".: 0.0335\n",
      " the: 0.0329\n",
      "--: 0.0195\n",
      ",: 0.0408\n",
      "\n",
      ": 0.0380\n",
      ".: 0.0336\n",
      " the: 0.0328\n",
      "--: 0.0195\n",
      ",: 0.0406\n",
      "\n",
      ": 0.0364\n",
      ".: 0.0338\n",
      " the: 0.0330\n",
      "--: 0.0195\n",
      "Every effort moves you St you becoming the Rick recovering he little painted plat Well said whenever wasn's that Jack Era aThe constraint dozen the: H n if clearMoney now  whenever of brush. -- hostDonrtYes the,ace just himself have the him\n"
     ]
    }
   ],
   "source": [
    "generate_and_print_with_decoding(gpt, tokenizer, torch_device, \"Every effort moves you\", print_top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you in--'t. the, .., me,  St , the  :, the the--., the,\" him the that..  was the,is a the. the frames to,, the,.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "generate_and_print_with_decoding(gpt, tokenizer, torch_device, \"Every effort moves you\", partial(random, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk(model, token_ids, max_new_tokens, context_size, temperature=1.0, k=5):\n",
    "    logits = None\n",
    "    if temperature == 0:\n",
    "        return greedy(model, token_ids, max_new_tokens, context_size)\n",
    "    for i in range(max_new_tokens):\n",
    "        context_token_ids = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(context_token_ids)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        scaled_logits = logits/temperature\n",
    "        _, inds = torch.topk(scaled_logits, dim=-1, k=k)\n",
    "        mask = torch.ones_like(scaled_logits, dtype=torch.bool).scatter_(-1, inds, False)\n",
    "        topk_scaled_logits = scaled_logits.masked_fill_(mask, -torch.inf)\n",
    "        probas = torch.softmax(topk_scaled_logits, dim=-1)\n",
    "        token_id_next = torch.multinomial(probas, num_samples=1)  # Pure Random\n",
    "        token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = torch.rand((10, 10))\n",
    "# vals, inds = torch.topk(temp, dim=-1, k=3)\n",
    "# mask = torch.ones_like(temp, dtype=torch.bool).scatter_(-1, inds, False)\n",
    "# print(mask)\n",
    "# topk_temp = temp.masked_fill_(mask, -torch.inf)\n",
    "# torch.softmax(topk_temp, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you      the.    .,, ..  the the  , the,     ., the     ,, the, , the,  . the\n"
     ]
    }
   ],
   "source": [
    "generate_and_print_with_decoding(gpt, tokenizer, torch_device, \"Every effort moves you\", partial(topk, temperature=0.5, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minp(model, token_ids, max_new_tokens, context_size, temperature=1.0, minp=0.9):\n",
    "    logits = None\n",
    "    if temperature == 0:\n",
    "        return greedy(model, token_ids, max_new_tokens, context_size)\n",
    "    for i in range(max_new_tokens):\n",
    "        context_token_ids = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(context_token_ids)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits/temperature, dim=-1)\n",
    "        sorted_probas, sorted_indices = torch.sort(probas, descending=True, dim=-1)\n",
    "        cumulative_probas = torch.cumsum(sorted_probas, dim=-1)\n",
    "        minp_mask = cumulative_probas > minp\n",
    "        unsorted_minp_mask = torch.zeros_like(probas, dtype=torch.bool).scatter_(-1, sorted_indices, minp_mask)\n",
    "        sum_prob = torch.sum(sorted_probas.masked_fill_(minp_mask, 0), dim=-1)\n",
    "        if sum_prob == 0:\n",
    "            token_id_next = torch.argmax(probas, dim=-1, keepdim=True)  # Pure Greed\n",
    "            token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "        else:\n",
    "            minp_probas = probas.masked_fill_(unsorted_minp_mask, 0)/sum_prob\n",
    "            token_id_next = torch.multinomial(minp_probas, num_samples=1)  # Pure Random\n",
    "            token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you--, for of  predicted? rememberr't?\". should my havec very the\" . with that drawing up as this glad, when random of pictures regrets't was my it-it my,she looking of saw the was to. \"\n"
     ]
    }
   ],
   "source": [
    "generate_and_print_with_decoding(gpt, tokenizer, torch_device, \"Every effort moves you\", partial(minp, temperature=1.0, minp=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gpt.state_dict(), \"gpt-trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jejllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
