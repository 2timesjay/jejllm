{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=torch_device)\n",
    "    print (x)\n",
    "else:\n",
    "    torch_device = torch.device(\"cpu\")\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "CONTEXT_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = torch.rand(8, CONTEXT_LENGTH, EMBEDDING_DIM).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = torch.matmul(input_embeddings, input_embeddings.transpose(1, 2))\n",
    "attn_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[89.6776, 62.3817, 55.2851, 66.0383],\n",
       "        [62.3817, 80.6503, 55.0130, 61.5921],\n",
       "        [55.2851, 55.0130, 67.5199, 54.2769],\n",
       "        [66.0383, 61.5921, 54.2769, 85.4145]], device='mps:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = attn_scores/torch.sum(attn_scores, dim=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.matmul(attn_weights, input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[130.9528, 124.2068, 110.9094, 128.1101],\n",
       "        [128.6789, 124.3847, 114.9565, 131.2061],\n",
       "        [128.7147, 134.5517, 131.0540, 134.1371],\n",
       "        [124.9101, 131.6775, 126.2380, 126.1799],\n",
       "        [123.9312, 124.4568, 116.6398, 123.6487],\n",
       "        [126.8249, 129.9419, 124.3546, 133.1391],\n",
       "        [125.9766, 128.0879, 128.4334, 129.7215],\n",
       "        [134.1459, 124.1152, 127.3237, 129.6205]], device='mps:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.shape.sum(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.1\n",
    "attn_scores = torch.matmul(input_embeddings, input_embeddings.transpose(1, 2))\n",
    "# attn_weights = torch.exp(temperature*attn_scores)/torch.sum(torch.exp(temperature*attn_scores), dim=2, keepdim=True)\n",
    "attn_weights = torch.softmax(temperature*attn_scores, dim=-1)\n",
    "context = torch.matmul(attn_weights, input_embeddings)  # Is this correct or should I transpose attn_weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]], device='mps:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights[0].sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jejllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
