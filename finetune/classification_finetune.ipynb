{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device not found. Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch_device = torch.device(\"mps:0\")\n",
    "    x = torch.ones(1, device=torch_device)\n",
    "    print (x)\n",
    "elif torch.cuda.is_available():\n",
    "    torch_device = torch.device(\"cuda\")\n",
    "    print (\"MPS device not found. Using CUDA.\")\n",
    "else:\n",
    "    torch_device = torch.device(\"cpu\")\n",
    "    print (\"No accelerator device found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "# Load the model\n",
    "gpt2_small = GPT2LMHeadModel.from_pretrained(\n",
    "    \"openai-community/gpt2\", \n",
    ").to(torch_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2SdpaAttention(\n",
       "  (c_attn): Conv1D(nf=2304, nx=768)\n",
       "  (c_proj): Conv1D(nf=768, nx=768)\n",
       "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py#L458\n",
    "gpt2_small.transformer.h[0].attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"../data/sms-spam-collection.zip\"\n",
    "extracted_path = \"../data/sms-spam-collection\"\n",
    "\n",
    "data_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(\n",
    "        url, zip_path, extracted_path, data_path\n",
    "):\n",
    "    if data_path.exists():\n",
    "        print(f\"Data already exists at {data_path}\")\n",
    "    else:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            with open(zip_path, \"wb\") as out_file:\n",
    "                out_file.write(response.read())\n",
    "\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extracted_path)\n",
    "        \n",
    "        original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "\n",
    "        os.rename(original_file_path, data_path)\n",
    "        print(f\"Data downloaded and extracted to {data_path}\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists at ../data/sms-spam-collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_path, sep=\"\\t\", header=None, names = [\"label\", \"text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     14.310259\n",
       "spam    23.911647\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df[\"word_count\"] = df[\"text\"].apply(word_count)\n",
    "\n",
    "df.groupby(\"label\").word_count.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " spam    602\n",
       " ham     593\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " spam    128\n",
       " ham     126\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = df.where(df[\"label\"] == \"spam\").dropna().reset_index(drop=True)\n",
    "ham_df = df.where(df[\"label\"] == \"ham\").dropna().reset_index(drop=True)\n",
    "ham_sample_df = ham_df.sample(747)\n",
    "balanced_df = pd.concat([spam_df, ham_sample_df])\n",
    "\n",
    "balanced_df.label.value_counts()\n",
    "train_df = balanced_df.sample(frac=0.8, random_state=1)\n",
    "test_df = balanced_df.drop(train_df.index)\n",
    "\n",
    "train_df.label.value_counts(),test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " spam    602\n",
       " ham     593\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " spam    128\n",
       " ham     126\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = balanced_df.sample(frac=0.8, random_state=1)\n",
    "test_df = balanced_df.drop(train_df.index)\n",
    "\n",
    "train_df.label.value_counts(),test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"../data/sms-spam-collection/train.tsv\", index=False, sep=\"\\t\")\n",
    "# test_df.to_csv(\"../data/sms-spam-collection/test.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_ratio=0.8, validation_ratio=0.1):\n",
    "    # Calculate the size of each set\n",
    "    train_size = int(len(df) * train_ratio)\n",
    "    validation_size = int(len(df) * validation_ratio)\n",
    "    \n",
    "    # Shuffle the DataFrame\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Split the DataFrame\n",
    "    train_df = df.iloc[:train_size]\n",
    "    validation_df = df.iloc[train_size:train_size + validation_size]\n",
    "    test_df = df.iloc[train_size + validation_size:]\n",
    "    \n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = random_split(balanced_df, train_ratio=0.8, validation_ratio=0.1)\n",
    "train_df.to_csv(\"../data/sms-spam-collection/train.tsv\", index=False, sep=\"\\t\")\n",
    "validation_df.to_csv(\"../data/sms-spam-collection/validation.tsv\", index=False, sep=\"\\t\")\n",
    "test_df.to_csv(\"../data/sms-spam-collection/test.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>-PLS STOP bootydelious (32/F) is inviting you ...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Convey my regards to him</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>4mths half price Orange line rental &amp; latest c...</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, I'll text you when I'm on the way</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor... U decide...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  word_count\n",
       "0  spam  -PLS STOP bootydelious (32/F) is inviting you ...        24.0\n",
       "1   ham                           Convey my regards to him         5.0\n",
       "2  spam  4mths half price Orange line rental & latest c...        26.0\n",
       "3   ham            Cool, I'll text you when I'm on the way         9.0\n",
       "4   ham                        Anything lor... U decide...         4.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file, sep=\"\\t\", header=0)\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"text\"]\n",
    "        ]\n",
    "        if max_length is None:\n",
    "            self.max_length = max(len(text) for text in self.encoded_texts)\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "        self.encoded_texts = torch.tensor(self.encoded_texts)\n",
    "        self.labels = torch.tensor(self.data[\"label\"].map({\"spam\": 1, \"ham\": 0}).values)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_texts[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>-PLS STOP bootydelious (32/F) is inviting you ...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Convey my regards to him</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>4mths half price Orange line rental &amp; latest c...</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, I'll text you when I'm on the way</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor... U decide...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi I'm sue. I am 20 years old and work as a la...</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thats cool. Where should i cum? On you or in y...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>ham</td>\n",
       "      <td>excellent. I spent  &amp;lt;#&amp;gt;  years in the Ai...</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>ham</td>\n",
       "      <td>I thk u dun haf 2 hint in e forum already lor....</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>ham</td>\n",
       "      <td>No chikku nt yet.. Ya i'm free</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  word_count\n",
       "0     spam  -PLS STOP bootydelious (32/F) is inviting you ...        24.0\n",
       "1      ham                           Convey my regards to him         5.0\n",
       "2     spam  4mths half price Orange line rental & latest c...        26.0\n",
       "3      ham            Cool, I'll text you when I'm on the way         9.0\n",
       "4      ham                        Anything lor... U decide...         4.0\n",
       "...    ...                                                ...         ...\n",
       "1190  spam  Hi I'm sue. I am 20 years old and work as a la...        35.0\n",
       "1191   ham  Thats cool. Where should i cum? On you or in y...        12.0\n",
       "1192   ham  excellent. I spent  &lt;#&gt;  years in the Ai...        21.0\n",
       "1193   ham  I thk u dun haf 2 hint in e forum already lor....        23.0\n",
       "1194   ham                     No chikku nt yet.. Ya i'm free         7.0\n",
       "\n",
       "[1195 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"../data/sms-spam-collection/train.tsv\", sep=\"\\t\", header=0)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1195\n",
       "unique       2\n",
       "top        ham\n",
       "freq       610\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   12,  6489,    50,  ..., 50256, 50256, 50256]), tensor(1))\n",
      "(tensor([ 3103,  3304,   616,  ..., 50256, 50256, 50256]), tensor(0))\n",
      "(tensor([   19,    76,  9998,  ..., 50256, 50256, 50256]), tensor(1))\n",
      "(tensor([34530,    11,   314,  ..., 50256, 50256, 50256]), tensor(0))\n",
      "(tensor([40028,   300,   273,  ..., 50256, 50256, 50256]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "spam_dataset = SpamDataset(\n",
    "    \"../data/sms-spam-collection/train.tsv\", \n",
    "    tokenizer, \n",
    "    max_length=1024,\n",
    "    pad_token_id=50256,\n",
    ")\n",
    "for i in range(5):\n",
    "    print(spam_dataset[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_dataset = SpamDataset(\n",
    "    \"../data/sms-spam-collection/train.tsv\", \n",
    "    tokenizer, \n",
    "    max_length=1024,\n",
    "    pad_token_id=50256,\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "validation_dataset = SpamDataset(\n",
    "    \"../data/sms-spam-collection/validation.tsv\", \n",
    "    tokenizer, \n",
    "    max_length=1024,\n",
    "    pad_token_id=50256,\n",
    ")\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "test_dataset = SpamDataset(\n",
    "    \"../data/sms-spam-collection/test.tsv\", \n",
    "    tokenizer, \n",
    "    max_length=1024,\n",
    "    pad_token_id=50256,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, token_ids, max_new_tokens, context_size):\n",
    "    logits = None\n",
    "    for i in range(max_new_tokens):\n",
    "        context_token_ids = token_ids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(context_token_ids)\n",
    "        if not isinstance(logits, torch.Tensor):\n",
    "            logits = logits.logits\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        token_id_next = torch.argmax(probas, dim=1, keepdim=True)  # Pure Greed\n",
    "        token_ids = torch.cat((token_ids, token_id_next), dim=1) \n",
    "\n",
    "    return token_ids\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special=set(['<|endoftext|>']))\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0).to(torch_device)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    decoded = tokenizer.decode(token_ids[0].tolist())\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def loss_fn(logits, targets):\n",
    "    vocab_size = logits.shape[-1]\n",
    "    loss = nn.CrossEntropyLoss()(logits.view(-1, vocab_size), targets.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch).logits\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits[:, -1, :],\n",
    "        target_batch,\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(dataloader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "    for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(dataloader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "    for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch).logits[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preloaded model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    gpt2_small, \n",
    "    text_to_token_ids(sample_input, tokenizer), \n",
    "    max_new_tokens=15, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner and you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or\n"
     ]
    }
   ],
   "source": [
    "sample_spam_q = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner and you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    gpt2_small, \n",
    "    text_to_token_ids(sample_spam_q, tokenizer), \n",
    "    max_new_tokens=15, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning with new head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpt2_small.to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters except the new head\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.transformer.h[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.transformer.ln_f.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.lm_head = nn.Linear(GPT_CONFIG_124M[\"emb_dim\"], num_classes).to(torch_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner and you have been specially selected to receive $1000 cash or a $2000 award.'\"\"\"\"\"\"\"\"!\"\"\"\"\"\"\n"
     ]
    }
   ],
   "source": [
    "sample_spam_q = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner and you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model, \n",
    "    text_to_token_ids(sample_spam_q, tokenizer), \n",
    "    max_new_tokens=15, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5000, Validation accuracy: 0.6500, Test accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_dataloader, model, torch_device, num_batches=10)\n",
    "validation_accuracy = calc_accuracy_loader(validation_dataloader, model, torch_device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_dataloader, model, torch_device, num_batches=10)\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}, Validation accuracy: {validation_accuracy:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 18, 18)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(validation_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 610, 1: 585})\n",
      "Counter({1: 89, 0: 60})\n",
      "Counter({0: 77, 1: 73})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter([label.item() for _, label in list(train_dataset)]))\n",
    "print(Counter([label.item() for _, label in list(validation_dataset)]))\n",
    "print(Counter([label.item() for _, label in list(test_dataset)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.6865, Validation loss: 3.1915, Test loss: 4.3300\n"
     ]
    }
   ],
   "source": [
    "train_loss = calc_loss_loader(train_dataloader, model, torch_device, num_batches=10)\n",
    "validation_loss = calc_loss_loader(validation_dataloader, model, torch_device, num_batches=10)\n",
    "test_loss = calc_loss_loader(test_dataloader, model, torch_device, num_batches=10)\n",
    "print(f\"Train loss: {train_loss:.4f}, Validation loss: {validation_loss:.4f}, Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_dataloader, validation_dataloader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_dataloader, model, device, num_batches=eval_iter)\n",
    "        validation_loss = calc_loss_loader(validation_dataloader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    print(f\"Train loss: {train_loss:.4f}, validation loss: {validation_loss:.4f}\")\n",
    "    return train_loss, validation_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    token_ids = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, token_ids, 50, context_size)\n",
    "    decoded_text = tokenizer.decode(token_ids[0].tolist())\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "        model, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "        train_acc = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_acc = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Epoch {epoch+1} complete\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.3558, validation loss: 2.9764\n",
      "Train loss: 0.8397, validation loss: 0.6396\n",
      "Train loss: 0.8220, validation loss: 0.6263\n",
      "Training accuracy: 0.6250\n",
      "Validation accuracy: 0.6750\n",
      "Epoch 1 complete\n",
      "Train loss: 0.6729, validation loss: 0.6263\n",
      "Train loss: 0.7317, validation loss: 0.6075\n",
      "Train loss: 0.6370, validation loss: 0.6028\n",
      "Training accuracy: 0.7500\n",
      "Validation accuracy: 0.9000\n",
      "Epoch 2 complete\n",
      "Train loss: 0.6134, validation loss: 0.6003\n",
      "Train loss: 0.7582, validation loss: 0.5764\n",
      "Train loss: 0.6608, validation loss: 0.5650\n",
      "Training accuracy: 0.5250\n",
      "Validation accuracy: 0.6500\n",
      "Epoch 3 complete\n",
      "Train loss: 0.7180, validation loss: 0.5742\n",
      "Train loss: 0.8599, validation loss: 0.5591\n",
      "Train loss: 0.6453, validation loss: 0.5080\n",
      "Training accuracy: 0.6500\n",
      "Validation accuracy: 0.7750\n",
      "Epoch 4 complete\n",
      "Train loss: 0.4907, validation loss: 0.4852\n",
      "Train loss: 0.7812, validation loss: 0.5434\n",
      "Train loss: 1.2284, validation loss: 0.5756\n",
      "Training accuracy: 0.6000\n",
      "Validation accuracy: 0.6750\n",
      "Epoch 5 complete\n",
      "Train loss: 1.0804, validation loss: 0.6150\n",
      "Train loss: 0.9600, validation loss: 0.5857\n",
      "Train loss: 1.1814, validation loss: 0.7333\n",
      "Training accuracy: 0.4750\n",
      "Validation accuracy: 0.6500\n",
      "Epoch 6 complete\n",
      "Train loss: 1.0427, validation loss: 0.9540\n",
      "Train loss: 1.3433, validation loss: 1.0756\n",
      "Train loss: 0.7530, validation loss: 0.5457\n",
      "Training accuracy: 0.6000\n",
      "Validation accuracy: 0.6750\n",
      "Epoch 7 complete\n",
      "Train loss: 0.9869, validation loss: 0.3729\n",
      "Train loss: 0.2789, validation loss: 0.1471\n",
      "Train loss: 0.4701, validation loss: 0.3064\n",
      "Training accuracy: 0.7000\n",
      "Validation accuracy: 0.8500\n",
      "Epoch 8 complete\n",
      "Train loss: 0.6512, validation loss: 0.2914\n",
      "Train loss: 0.3671, validation loss: 0.1470\n",
      "Train loss: 0.2873, validation loss: 0.1336\n",
      "Training accuracy: 0.8750\n",
      "Validation accuracy: 0.9250\n",
      "Epoch 9 complete\n",
      "Train loss: 0.3878, validation loss: 0.1351\n",
      "Train loss: 0.1434, validation loss: 0.1017\n",
      "Train loss: 0.2662, validation loss: 0.0878\n",
      "Training accuracy: 0.7750\n",
      "Validation accuracy: 0.9500\n",
      "Epoch 10 complete\n",
      "Training time: 147.18 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.00005, weight_decay = 0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_dataloader, validation_dataloader, optimizer, torch_device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy_loader(test_dataloader, model, torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jejllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
